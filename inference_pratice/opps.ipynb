{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "total = [0]\n",
    "def my_matmult(m1, m2):\n",
    "    ans_mat = np.empty((0,m2.shape[1]))\n",
    "    for row in m1:\n",
    "        ans_row = np.array([])\n",
    "        for col in m2.T:\n",
    "            ans_row = np.append(ans_row, np.dot(row, col))\n",
    "            total[0] += len(row)*2\n",
    "        ans_mat = np.vstack((ans_mat,ans_row))\n",
    "    return ans_mat\n",
    "\n",
    "a = np.random.rand(3, 2)\n",
    "b = np.random.rand(2, 3)\n",
    "\n",
    "print(np.array_equal(a@b, my_matmult(a,b)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def tensor_product(m1, m2):\n",
    "  ans = np.empty( (0, m1.shape[-2], m2.shape[-1]) )\n",
    "  for i in range(m1.shape[0]):\n",
    "    matmult = np.expand_dims(my_matmult(m1[i], m2[i]), axis=0)\n",
    "    ans = np.vstack((ans, matmult))\n",
    "  return ans\n",
    "\n",
    "a = np.random.rand(2, 3, 4)\n",
    "b = np.random.rand(2, 4, 2)\n",
    "\n",
    "print(np.allclose(tensor_product(a,b), a @ b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[24576]\n"
     ]
    }
   ],
   "source": [
    "def nd_tensor_product(m1, m2):\n",
    "  ans_shape = m1.shape[:-2] + (m1.shape[-2], m2.shape[-1])\n",
    "  ans = np.empty(ans_shape)\n",
    "  for i in range(m1.shape[0]):\n",
    "    if len(m1.shape) == 3:\n",
    "        ans[i] = my_matmult(m1[i], m2[i])\n",
    "\n",
    "    else:\n",
    "        ans[i] = nd_tensor_product(m1[i], m2[i])\n",
    "  return ans\n",
    "\n",
    "a = np.random.rand(12, 4, 64)\n",
    "b = np.random.rand(12, 64, 4)\n",
    "\n",
    "total = [0]\n",
    "\n",
    "print(np.allclose(nd_tensor_product(a,b), a @ b))\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matix_absmax_quantization(m1, int_type=np.int8):\n",
    "    data_max = np.iinfo(int_type).max\n",
    "    norm_range = math.floor((data_max)**(1/2)/ max(m1.shape))\n",
    "    quantification_constant = norm_range/np.max(abs(m1))\n",
    "    new_type = (m1 * quantification_constant).astype(int_type)\n",
    "    assert np.all((new_type >= -1*norm_range) & (new_type <= norm_range))\n",
    "\n",
    "    return new_type, quantification_constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_quant_matmul(m1, m2):\n",
    "    m1, m1_const = matix_absmax_quantization(m1, qualtization_type)\n",
    "    m2, m2_const = matix_absmax_quantization(m2, qualtization_type)\n",
    "\n",
    "    ans = np.matmul(m1,m2)\n",
    "\n",
    "    ans = (ans.astype(np.float64))/ (m1_const * m2_const)\n",
    "    return ans\n",
    "\n",
    "def vector_quant_matmul(m1, m2):\n",
    "    matrix = np.empty((m1.shape[0], m2.shape[-1]))\n",
    "    for row_num in range(len(m1)):\n",
    "        for col_num in range(m2.shape[-1]):\n",
    "            row = m1[row_num]\n",
    "            col = m2[:, col_num]\n",
    "            int_row, row_const = matix_absmax_quantization(row, qualtization_type)\n",
    "            int_col, col_const = matix_absmax_quantization(col, qualtization_type)\n",
    "            int_dot = np.dot(int_row, int_col)\n",
    "            float_dot = int_dot.astype(np.float64)* 1/(row_const * col_const)\n",
    "            if np.isnan(float_dot):\n",
    "                float_dot = 0\n",
    "            matrix[row_num][col_num] = float_dot\n",
    "    return matrix\n",
    "\n",
    "def nd_tensor_product(m1, m2, matrix=True):\n",
    "    ans_shape = m1.shape[:-2] + (m1.shape[-2], m2.shape[-1])\n",
    "    ans = np.empty(ans_shape)\n",
    "    if len(ans_shape) < 3:\n",
    "        return matrix_quant_matmul(m1, m2) if matrix else vector_quant_matmul(m1, m2)\n",
    "    else:\n",
    "        for i in range(ans_shape[0]):\n",
    "            ans[i] = nd_tensor_product(m1[i], m2[i], matrix=matrix)\n",
    "    return ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% vec better 0.882\n",
      "mtx loss 8.205929315715846e-08\n",
      "vec loss 2.285062211066629e-08\n"
     ]
    }
   ],
   "source": [
    "vec_smaller = 0\n",
    "iterations = 1000\n",
    "qualtization_type = np.int64\n",
    "\n",
    "matrix_diff = 0\n",
    "vec_diff = 0\n",
    "\n",
    "\n",
    "for _ in range(iterations):\n",
    "    a = np.random.uniform(-20, 20, size=(2, 10, 4))\n",
    "    b = np.random.uniform(-20, 20, size=(2, 4, 10))\n",
    "\n",
    "    actual = a @ b\n",
    "\n",
    "    mx_quantized = nd_tensor_product(a,b, matrix = True)\n",
    "    # print(f\"{mx_quantized=}\")\n",
    "    mx_loss = np.abs(np.mean(mx_quantized - actual))\n",
    "    matrix_diff += mx_loss\n",
    "    # print(f'matrix loss: {mx_loss}')\n",
    "\n",
    "    vec_quantized = nd_tensor_product(a,b, matrix = False)\n",
    "    # print(f\"{vec_quantized=}\")\n",
    "    vec_loss = np.abs(np.mean(vec_quantized - actual))\n",
    "    # print(vec_loss)\n",
    "    vec_diff += vec_loss\n",
    "    # print(f'vec loss: {vec_loss}')\n",
    "    if vec_loss < mx_loss:\n",
    "        vec_smaller += 1\n",
    "\n",
    "\n",
    "print(f'% vec better {vec_smaller/iterations}')\n",
    "print(f'mtx loss {matrix_diff/iterations}')\n",
    "print(f'vec loss {vec_diff/iterations}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zeropoint Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -3.81947852  16.85851024 -16.94883347  -9.36529621   1.06620353\n",
      " -13.45042167   2.14239435 -17.07961161  -5.89922935  -1.76337706]\n",
      "<class 'numpy.int8'>\n",
      "[ -3.85962954  16.90251559 -16.90251559  -9.31634717   1.06472539\n",
      " -13.44215807   2.12945078 -17.03560626  -5.85598965  -1.73017876]\n"
     ]
    }
   ],
   "source": [
    "def zeropoint_quantization(x, data_type):\n",
    "    data_range = np.iinfo(data_type).max- np.iinfo(data_type).min\n",
    "    q_c = data_range / (np.max(x)- np. min(x))\n",
    "    z_p = -1* np.round(q_c * np.min(x)) - 128\n",
    "    type_x = np.round(q_c * x + z_p).astype(data_type)\n",
    "    return ((type_x - z_p )/ q_c).astype(np.float64)\n",
    "\n",
    "\n",
    "a = np.random.uniform(-20, 20, size=(10))\n",
    "print(a)\n",
    "print(zeropoint_quantization(a, np.int8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeropoint_quantization(x, data_type):\n",
    "    data_range = np.iinfo(data_type).max- np.iinfo(data_type).min\n",
    "    q_c = data_range / (np.max(x)- np. min(x))\n",
    "    z_p = -1* np.round(q_c * np.min(x)) + np.iinfo(data_type).min\n",
    "    type_x = np.round(q_c * x + z_p).astype(data_type)\n",
    "    return type_x, q_c, z_p\n",
    "\n",
    "\n",
    "# a = np.random.uniform(-20, 20, size=(10))\n",
    "# print(a)\n",
    "# print(zeropoint_quantization(a, np.int8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_quant_matmul(m1, m2):\n",
    "    matrix = np.empty((m1.shape[0], m2.shape[-1]))\n",
    "    for row_num in range(len(m1)):\n",
    "        for col_num in range(m2.shape[-1]):\n",
    "            row = m1[row_num]\n",
    "            col = m2[:, col_num]\n",
    "            int_row, row_const, row_zero = zeropoint_quantization(row, qualtization_type)\n",
    "            int_col, col_const, col_zero = zeropoint_quantization(col, qualtization_type)\n",
    "            int_dot = np.dot(int_row - row_zero, int_col- col_zero)\n",
    "            float_dot = (int_dot /(row_const * col_const)).astype(np.float64)\n",
    "            if np.isnan(float_dot):\n",
    "                float_dot = 0\n",
    "            matrix[row_num][col_num] = float_dot\n",
    "    return matrix\n",
    "\n",
    "def nd_tensor_product(m1, m2, matrix=True):\n",
    "    ans_shape = m1.shape[:-2] + (m1.shape[-2], m2.shape[-1])\n",
    "    ans = np.empty(ans_shape)\n",
    "    if len(ans_shape) < 3:\n",
    "        return matrix_quant_matmul(m1, m2) if matrix else vector_quant_matmul(m1, m2)\n",
    "    else:\n",
    "        for i in range(ans_shape[0]):\n",
    "            ans[i] = nd_tensor_product(m1[i], m2[i], matrix=matrix)\n",
    "    return ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-115.50278182  -46.11525114   35.05039982 -483.37567864]\n",
      " [   6.81018286  256.69913419 -450.89811225   58.91757364]]\n",
      "[[-115.50278179  -46.11525112   35.05039982 -483.37567866]\n",
      " [   6.8101829   256.69913423 -450.89811231   58.91757358]]\n"
     ]
    }
   ],
   "source": [
    "qualtization_type = np.int32\n",
    "a = np.random.uniform(-20, 20, size=(2,3))\n",
    "b = np.random.uniform(-20, 20, size=(3,4))\n",
    "\n",
    "actual = a @ b\n",
    "\n",
    "vec_quantized = nd_tensor_product(a,b, matrix = False)\n",
    "\n",
    "print(actual)\n",
    "print(vec_quantized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zeropoint or absmax Quantization together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matix_absmax_quantization(m1, int_type=np.int8):\n",
    "    data_max = np.iinfo(int_type).max\n",
    "    norm_range = math.floor((data_max)**(1/2)/ max(m1.shape))\n",
    "    quantification_constant = norm_range/np.max(abs(m1))\n",
    "    new_type = (m1 * quantification_constant).astype(int_type)\n",
    "    assert np.all((new_type >= -1*norm_range) & (new_type <= norm_range))\n",
    "    return new_type, quantification_constant\n",
    "\n",
    "def zeropoint_quantization(x, data_type):\n",
    "    data_range = np.iinfo(data_type).max- np.iinfo(data_type).min\n",
    "    q_c = data_range / (np.max(x)- np. min(x))\n",
    "    z_p = -1* np.round(q_c * np.min(x)) + np.iinfo(data_type).min\n",
    "    type_x = np.round(q_c * x + z_p).astype(data_type)\n",
    "    return type_x, q_c, z_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_quant_matmul(m1, m2, quantization_method):\n",
    "    matrix = np.empty((m1.shape[0], m2.shape[-1]))\n",
    "    for row_num in range(len(m1)):\n",
    "        for col_num in range(m2.shape[-1]):\n",
    "            row = m1[row_num]\n",
    "            col = m2[:, col_num]\n",
    "            if quantization_method == 'absmax':\n",
    "                int_row, row_const = matix_absmax_quantization(row, qualtization_type)\n",
    "                int_col, col_const = matix_absmax_quantization(col, qualtization_type)\n",
    "                int_dot = np.dot(int_row, int_col)\n",
    "                float_dot = int_dot.astype(np.float64)* 1/(row_const * col_const)\n",
    "            elif quantization_method == 'zeropoint':\n",
    "                int_row, row_const, row_zero = zeropoint_quantization(row, qualtization_type)\n",
    "                int_col, col_const, col_zero = zeropoint_quantization(col, qualtization_type)\n",
    "                int_dot = np.dot(int_row - row_zero, int_col- col_zero) # TODO Still multiplying in float64\n",
    "                float_dot = (int_dot /(row_const * col_const)).astype(np.float64)\n",
    "            if np.isnan(float_dot):\n",
    "                float_dot = 0\n",
    "            matrix[row_num][col_num] = float_dot\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def nd_tensor_product(m1, m2, quantization_method = 'absmax'):\n",
    "    ans_shape = m1.shape[:-2] + (m1.shape[-2], m2.shape[-1])\n",
    "    ans = np.empty(ans_shape)\n",
    "    if len(ans_shape) < 3:\n",
    "        return vector_quant_matmul(m1, m2, quantization_method)\n",
    "    else:\n",
    "        for i in range(ans_shape[0]):\n",
    "            ans[i] = nd_tensor_product(m1[i], m2[i], quantization_method=quantization_method)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% vec better 0.997\n",
      "abs loss 7.695771877807612\n",
      "zeropoint loss 0.05291885510640937\n"
     ]
    }
   ],
   "source": [
    "iterations = 1000\n",
    "qualtization_type = np.int8\n",
    "\n",
    "absmax_diff = 0\n",
    "zeropoint_diff = 0\n",
    "\n",
    "zeropoint_smaller = 0\n",
    "for _ in range(iterations):\n",
    "    a = np.random.uniform(-20, 20, size=(2, 10, 4))\n",
    "    b = np.random.uniform(-20, 20, size=(2, 4, 10))\n",
    "\n",
    "    actual = a @ b\n",
    "\n",
    "    absmax_quantized = nd_tensor_product(a,b, quantization_method = 'absmax')\n",
    "    absmax_loss = np.abs(np.mean(absmax_quantized - actual))\n",
    "    absmax_diff += absmax_loss\n",
    "\n",
    "    zeropoint_quantized = nd_tensor_product(a,b, quantization_method = 'zeropoint')\n",
    "    zeropoint_loss = np.abs(np.mean(zeropoint_quantized - actual))\n",
    "    zeropoint_diff += zeropoint_loss\n",
    "    if zeropoint_loss < absmax_loss:\n",
    "        zeropoint_smaller += 1\n",
    "\n",
    "\n",
    "print(f'% vec better {zeropoint_smaller/iterations}')\n",
    "print(f'abs loss {absmax_diff/iterations}')\n",
    "print(f'zeropoint loss {zeropoint_diff/iterations}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight\n",
      "transformer.wpe.weight\n",
      "transformer.h.0.ln_1.weight\n",
      "transformer.h.0.ln_1.bias\n",
      "transformer.h.0.attn.c_attn.weight\n",
      "transformer.h.0.attn.c_attn.bias\n",
      "transformer.h.0.attn.c_proj.weight\n",
      "transformer.h.0.attn.c_proj.bias\n",
      "transformer.h.0.ln_2.weight\n",
      "transformer.h.0.ln_2.bias\n",
      "transformer.h.0.mlp.c_fc.weight\n",
      "transformer.h.0.mlp.c_fc.bias\n",
      "transformer.h.0.mlp.c_proj.weight\n",
      "transformer.h.0.mlp.c_proj.bias\n",
      "transformer.h.1.ln_1.weight\n",
      "transformer.h.1.ln_1.bias\n",
      "transformer.h.1.attn.c_attn.weight\n",
      "transformer.h.1.attn.c_attn.bias\n",
      "transformer.h.1.attn.c_proj.weight\n",
      "transformer.h.1.attn.c_proj.bias\n",
      "transformer.h.1.ln_2.weight\n",
      "transformer.h.1.ln_2.bias\n",
      "transformer.h.1.mlp.c_fc.weight\n",
      "transformer.h.1.mlp.c_fc.bias\n",
      "transformer.h.1.mlp.c_proj.weight\n",
      "transformer.h.1.mlp.c_proj.bias\n",
      "transformer.h.2.ln_1.weight\n",
      "transformer.h.2.ln_1.bias\n",
      "transformer.h.2.attn.c_attn.weight\n",
      "transformer.h.2.attn.c_attn.bias\n",
      "transformer.h.2.attn.c_proj.weight\n",
      "transformer.h.2.attn.c_proj.bias\n",
      "transformer.h.2.ln_2.weight\n",
      "transformer.h.2.ln_2.bias\n",
      "transformer.h.2.mlp.c_fc.weight\n",
      "transformer.h.2.mlp.c_fc.bias\n",
      "transformer.h.2.mlp.c_proj.weight\n",
      "transformer.h.2.mlp.c_proj.bias\n",
      "transformer.h.3.ln_1.weight\n",
      "transformer.h.3.ln_1.bias\n",
      "transformer.h.3.attn.c_attn.weight\n",
      "transformer.h.3.attn.c_attn.bias\n",
      "transformer.h.3.attn.c_proj.weight\n",
      "transformer.h.3.attn.c_proj.bias\n",
      "transformer.h.3.ln_2.weight\n",
      "transformer.h.3.ln_2.bias\n",
      "transformer.h.3.mlp.c_fc.weight\n",
      "transformer.h.3.mlp.c_fc.bias\n",
      "transformer.h.3.mlp.c_proj.weight\n",
      "transformer.h.3.mlp.c_proj.bias\n",
      "transformer.h.4.ln_1.weight\n",
      "transformer.h.4.ln_1.bias\n",
      "transformer.h.4.attn.c_attn.weight\n",
      "transformer.h.4.attn.c_attn.bias\n",
      "transformer.h.4.attn.c_proj.weight\n",
      "transformer.h.4.attn.c_proj.bias\n",
      "transformer.h.4.ln_2.weight\n",
      "transformer.h.4.ln_2.bias\n",
      "transformer.h.4.mlp.c_fc.weight\n",
      "transformer.h.4.mlp.c_fc.bias\n",
      "transformer.h.4.mlp.c_proj.weight\n",
      "transformer.h.4.mlp.c_proj.bias\n",
      "transformer.h.5.ln_1.weight\n",
      "transformer.h.5.ln_1.bias\n",
      "transformer.h.5.attn.c_attn.weight\n",
      "transformer.h.5.attn.c_attn.bias\n",
      "transformer.h.5.attn.c_proj.weight\n",
      "transformer.h.5.attn.c_proj.bias\n",
      "transformer.h.5.ln_2.weight\n",
      "transformer.h.5.ln_2.bias\n",
      "transformer.h.5.mlp.c_fc.weight\n",
      "transformer.h.5.mlp.c_fc.bias\n",
      "transformer.h.5.mlp.c_proj.weight\n",
      "transformer.h.5.mlp.c_proj.bias\n",
      "transformer.h.6.ln_1.weight\n",
      "transformer.h.6.ln_1.bias\n",
      "transformer.h.6.attn.c_attn.weight\n",
      "transformer.h.6.attn.c_attn.bias\n",
      "transformer.h.6.attn.c_proj.weight\n",
      "transformer.h.6.attn.c_proj.bias\n",
      "transformer.h.6.ln_2.weight\n",
      "transformer.h.6.ln_2.bias\n",
      "transformer.h.6.mlp.c_fc.weight\n",
      "transformer.h.6.mlp.c_fc.bias\n",
      "transformer.h.6.mlp.c_proj.weight\n",
      "transformer.h.6.mlp.c_proj.bias\n",
      "transformer.h.7.ln_1.weight\n",
      "transformer.h.7.ln_1.bias\n",
      "transformer.h.7.attn.c_attn.weight\n",
      "transformer.h.7.attn.c_attn.bias\n",
      "transformer.h.7.attn.c_proj.weight\n",
      "transformer.h.7.attn.c_proj.bias\n",
      "transformer.h.7.ln_2.weight\n",
      "transformer.h.7.ln_2.bias\n",
      "transformer.h.7.mlp.c_fc.weight\n",
      "transformer.h.7.mlp.c_fc.bias\n",
      "transformer.h.7.mlp.c_proj.weight\n",
      "transformer.h.7.mlp.c_proj.bias\n",
      "transformer.h.8.ln_1.weight\n",
      "transformer.h.8.ln_1.bias\n",
      "transformer.h.8.attn.c_attn.weight\n",
      "transformer.h.8.attn.c_attn.bias\n",
      "transformer.h.8.attn.c_proj.weight\n",
      "transformer.h.8.attn.c_proj.bias\n",
      "transformer.h.8.ln_2.weight\n",
      "transformer.h.8.ln_2.bias\n",
      "transformer.h.8.mlp.c_fc.weight\n",
      "transformer.h.8.mlp.c_fc.bias\n",
      "transformer.h.8.mlp.c_proj.weight\n",
      "transformer.h.8.mlp.c_proj.bias\n",
      "transformer.h.9.ln_1.weight\n",
      "transformer.h.9.ln_1.bias\n",
      "transformer.h.9.attn.c_attn.weight\n",
      "transformer.h.9.attn.c_attn.bias\n",
      "transformer.h.9.attn.c_proj.weight\n",
      "transformer.h.9.attn.c_proj.bias\n",
      "transformer.h.9.ln_2.weight\n",
      "transformer.h.9.ln_2.bias\n",
      "transformer.h.9.mlp.c_fc.weight\n",
      "transformer.h.9.mlp.c_fc.bias\n",
      "transformer.h.9.mlp.c_proj.weight\n",
      "transformer.h.9.mlp.c_proj.bias\n",
      "transformer.h.10.ln_1.weight\n",
      "transformer.h.10.ln_1.bias\n",
      "transformer.h.10.attn.c_attn.weight\n",
      "transformer.h.10.attn.c_attn.bias\n",
      "transformer.h.10.attn.c_proj.weight\n",
      "transformer.h.10.attn.c_proj.bias\n",
      "transformer.h.10.ln_2.weight\n",
      "transformer.h.10.ln_2.bias\n",
      "transformer.h.10.mlp.c_fc.weight\n",
      "transformer.h.10.mlp.c_fc.bias\n",
      "transformer.h.10.mlp.c_proj.weight\n",
      "transformer.h.10.mlp.c_proj.bias\n",
      "transformer.h.11.ln_1.weight\n",
      "transformer.h.11.ln_1.bias\n",
      "transformer.h.11.attn.c_attn.weight\n",
      "transformer.h.11.attn.c_attn.bias\n",
      "transformer.h.11.attn.c_proj.weight\n",
      "transformer.h.11.attn.c_proj.bias\n",
      "transformer.h.11.ln_2.weight\n",
      "transformer.h.11.ln_2.bias\n",
      "transformer.h.11.mlp.c_fc.weight\n",
      "transformer.h.11.mlp.c_fc.bias\n",
      "transformer.h.11.mlp.c_proj.weight\n",
      "transformer.h.11.mlp.c_proj.bias\n",
      "transformer.ln_f.weight\n",
      "transformer.ln_f.bias\n",
      "lm_head.weight\n"
     ]
    }
   ],
   "source": [
    "model_name = 'gpt2'\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torchscript=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "state_dict = model.state_dict()\n",
    "parameters = {}\n",
    "for name, val in state_dict.items():\n",
    "    parameters[name] = np.round(val.numpy().astype(np.float64), 4)\n",
    "\n",
    "for name in parameters:\n",
    "    print (name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3072\n",
      "2.5517430013020834\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weight = parameters['transformer.h.1.mlp.c_fc.weight']\n",
    "sums = []\n",
    "for i in range(weight.shape[-1]):\n",
    "    sums.append(np.abs(sum(weight[:, i])))\n",
    "\n",
    "print(len(sums))\n",
    "print(np.mean(sums))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(sums)), sums, color='skyblue')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Sums of Weights in GPT-2 Transformer Layer')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Sum of Weights')\n",
    "\n",
    "# Display the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242: 90.1863\n",
      "293: 33.100600000000014\n",
      "368: 29.800499999999982\n",
      "697: 21.002100000000013\n",
      "706: 31.836299999999977\n",
      "975: 24.615499999999976\n",
      "1120: 91.34309999999996\n",
      "1467: 21.616400000000024\n",
      "1602: 24.10220000000004\n",
      "1794: 26.607300000000013\n",
      "1859: 24.122600000000006\n",
      "2200: 24.933199999999974\n",
      "2355: 22.180799999999987\n",
      "2401: 80.73549999999996\n",
      "2511: 24.415899999999965\n",
      "2995: 24.912099999999995\n"
     ]
    }
   ],
   "source": [
    "average = np.mean(sums)\n",
    "for index, item in enumerate(sums):\n",
    "    if item > average*8:\n",
    "        print(f\"{index}: {item}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
