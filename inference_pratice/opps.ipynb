{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "total = [0]\n",
    "def my_matmult(m1, m2):\n",
    "    ans_mat = np.empty((0,m2.shape[1]))\n",
    "    for row in m1:\n",
    "        ans_row = np.array([])\n",
    "        for col in m2.T:\n",
    "            ans_row = np.append(ans_row, np.dot(row, col))\n",
    "            total[0] += len(row)*2\n",
    "        ans_mat = np.vstack((ans_mat,ans_row))\n",
    "    return ans_mat\n",
    "\n",
    "a = np.random.rand(3, 2)\n",
    "b = np.random.rand(2, 3)\n",
    "\n",
    "print(np.array_equal(a@b, my_matmult(a,b)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def tensor_product(m1, m2):\n",
    "  ans = np.empty( (0, m1.shape[-2], m2.shape[-1]) )\n",
    "  for i in range(m1.shape[0]):\n",
    "    matmult = np.expand_dims(my_matmult(m1[i], m2[i]), axis=0)\n",
    "    ans = np.vstack((ans, matmult))\n",
    "  return ans\n",
    "\n",
    "a = np.random.rand(2, 3, 4)\n",
    "b = np.random.rand(2, 4, 2)\n",
    "\n",
    "print(np.allclose(tensor_product(a,b), a @ b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[24576]\n"
     ]
    }
   ],
   "source": [
    "def nd_tensor_product(m1, m2):\n",
    "  ans_shape = m1.shape[:-2] + (m1.shape[-2], m2.shape[-1])\n",
    "  ans = np.empty(ans_shape)\n",
    "  for i in range(m1.shape[0]):\n",
    "    if len(m1.shape) == 3:\n",
    "        ans[i] = my_matmult(m1[i], m2[i])\n",
    "\n",
    "    else:\n",
    "        ans[i] = nd_tensor_product(m1[i], m2[i])\n",
    "  return ans\n",
    "\n",
    "a = np.random.rand(12, 4, 64)\n",
    "b = np.random.rand(12, 64, 4)\n",
    "\n",
    "total = [0]\n",
    "\n",
    "print(np.allclose(nd_tensor_product(a,b), a @ b))\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matix_absmax_quantization(m1, int_type=np.int8):\n",
    "    data_max = np.iinfo(int_type).max\n",
    "    norm_range = math.floor((data_max)**(1/2)/ max(m1.shape))\n",
    "    quantification_constant = norm_range/np.max(abs(m1))\n",
    "    new_type = (m1 * quantification_constant).astype(int_type)\n",
    "    assert np.all((new_type >= -1*norm_range) & (new_type <= norm_range))\n",
    "\n",
    "    return new_type, quantification_constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_quant_matmul(m1, m2):\n",
    "    m1, m1_const = matix_absmax_quantization(m1, qualtization_type)\n",
    "    m2, m2_const = matix_absmax_quantization(m2, qualtization_type)\n",
    "\n",
    "    ans = np.matmul(m1,m2)\n",
    "\n",
    "    ans = (ans.astype(np.float64))/ (m1_const * m2_const)\n",
    "    return ans\n",
    "\n",
    "def vector_quant_matmul(m1, m2):\n",
    "    matrix = np.empty((m1.shape[0], m2.shape[-1]))\n",
    "    for row_num in range(len(m1)):\n",
    "        for col_num in range(m2.shape[-1]):\n",
    "            row = m1[row_num]\n",
    "            col = m2[:, col_num]\n",
    "            int_row, row_const = matix_absmax_quantization(row, qualtization_type)\n",
    "            int_col, col_const = matix_absmax_quantization(col, qualtization_type)\n",
    "            int_dot = np.dot(int_row, int_col)\n",
    "            float_dot = int_dot.astype(np.float64)* 1/(row_const * col_const)\n",
    "            if np.isnan(float_dot):\n",
    "                float_dot = 0\n",
    "            matrix[row_num][col_num] = float_dot\n",
    "    return matrix\n",
    "\n",
    "def nd_tensor_product(m1, m2, matrix=True):\n",
    "    ans_shape = m1.shape[:-2] + (m1.shape[-2], m2.shape[-1])\n",
    "    ans = np.empty(ans_shape)\n",
    "    if len(ans_shape) < 3:\n",
    "        return matrix_quant_matmul(m1, m2) if matrix else vector_quant_matmul(m1, m2)\n",
    "    else:\n",
    "        for i in range(ans_shape[0]):\n",
    "            ans[i] = nd_tensor_product(m1[i], m2[i], matrix=matrix)\n",
    "    return ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% vec better 0.882\n",
      "mtx loss 8.205929315715846e-08\n",
      "vec loss 2.285062211066629e-08\n"
     ]
    }
   ],
   "source": [
    "vec_smaller = 0\n",
    "iterations = 1000\n",
    "qualtization_type = np.int64\n",
    "\n",
    "matrix_diff = 0\n",
    "vec_diff = 0\n",
    "\n",
    "\n",
    "for _ in range(iterations):\n",
    "    a = np.random.uniform(-20, 20, size=(2, 10, 4))\n",
    "    b = np.random.uniform(-20, 20, size=(2, 4, 10))\n",
    "\n",
    "    actual = a @ b\n",
    "\n",
    "    mx_quantized = nd_tensor_product(a,b, matrix = True)\n",
    "    # print(f\"{mx_quantized=}\")\n",
    "    mx_loss = np.abs(np.mean(mx_quantized - actual))\n",
    "    matrix_diff += mx_loss\n",
    "    # print(f'matrix loss: {mx_loss}')\n",
    "\n",
    "    vec_quantized = nd_tensor_product(a,b, matrix = False)\n",
    "    # print(f\"{vec_quantized=}\")\n",
    "    vec_loss = np.abs(np.mean(vec_quantized - actual))\n",
    "    # print(vec_loss)\n",
    "    vec_diff += vec_loss\n",
    "    # print(f'vec loss: {vec_loss}')\n",
    "    if vec_loss < mx_loss:\n",
    "        vec_smaller += 1\n",
    "\n",
    "\n",
    "print(f'% vec better {vec_smaller/iterations}')\n",
    "print(f'mtx loss {matrix_diff/iterations}')\n",
    "print(f'vec loss {vec_diff/iterations}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zeropoint Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -3.81947852  16.85851024 -16.94883347  -9.36529621   1.06620353\n",
      " -13.45042167   2.14239435 -17.07961161  -5.89922935  -1.76337706]\n",
      "<class 'numpy.int8'>\n",
      "[ -3.85962954  16.90251559 -16.90251559  -9.31634717   1.06472539\n",
      " -13.44215807   2.12945078 -17.03560626  -5.85598965  -1.73017876]\n"
     ]
    }
   ],
   "source": [
    "def zeropoint_quantization(x, data_type):\n",
    "    data_range = np.iinfo(data_type).max- np.iinfo(data_type).min\n",
    "    q_c = data_range / (np.max(x)- np. min(x))\n",
    "    z_p = -1* np.round(q_c * np.min(x)) - 128\n",
    "    type_x = np.round(q_c * x + z_p).astype(data_type)\n",
    "    return ((type_x - z_p )/ q_c).astype(np.float64)\n",
    "\n",
    "\n",
    "a = np.random.uniform(-20, 20, size=(10))\n",
    "print(a)\n",
    "print(zeropoint_quantization(a, np.int8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeropoint_quantization(x, data_type):\n",
    "    data_range = np.iinfo(data_type).max- np.iinfo(data_type).min\n",
    "    q_c = data_range / (np.max(x)- np. min(x))\n",
    "    z_p = -1* np.round(q_c * np.min(x)) + np.iinfo(data_type).min\n",
    "    type_x = np.round(q_c * x + z_p).astype(data_type)\n",
    "    return type_x, q_c, z_p\n",
    "\n",
    "\n",
    "# a = np.random.uniform(-20, 20, size=(10))\n",
    "# print(a)\n",
    "# print(zeropoint_quantization(a, np.int8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_quant_matmul(m1, m2):\n",
    "    matrix = np.empty((m1.shape[0], m2.shape[-1]))\n",
    "    for row_num in range(len(m1)):\n",
    "        for col_num in range(m2.shape[-1]):\n",
    "            row = m1[row_num]\n",
    "            col = m2[:, col_num]\n",
    "            int_row, row_const, row_zero = zeropoint_quantization(row, qualtization_type)\n",
    "            int_col, col_const, col_zero = zeropoint_quantization(col, qualtization_type)\n",
    "            int_dot = np.dot(int_row - row_zero, int_col- col_zero)\n",
    "            float_dot = (int_dot /(row_const * col_const)).astype(np.float64)\n",
    "            if np.isnan(float_dot):\n",
    "                float_dot = 0\n",
    "            matrix[row_num][col_num] = float_dot\n",
    "    return matrix\n",
    "\n",
    "def nd_tensor_product(m1, m2, matrix=True):\n",
    "    ans_shape = m1.shape[:-2] + (m1.shape[-2], m2.shape[-1])\n",
    "    ans = np.empty(ans_shape)\n",
    "    if len(ans_shape) < 3:\n",
    "        return matrix_quant_matmul(m1, m2) if matrix else vector_quant_matmul(m1, m2)\n",
    "    else:\n",
    "        for i in range(ans_shape[0]):\n",
    "            ans[i] = nd_tensor_product(m1[i], m2[i], matrix=matrix)\n",
    "    return ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-115.50278182  -46.11525114   35.05039982 -483.37567864]\n",
      " [   6.81018286  256.69913419 -450.89811225   58.91757364]]\n",
      "[[-115.50278179  -46.11525112   35.05039982 -483.37567866]\n",
      " [   6.8101829   256.69913423 -450.89811231   58.91757358]]\n"
     ]
    }
   ],
   "source": [
    "qualtization_type = np.int32\n",
    "a = np.random.uniform(-20, 20, size=(2,3))\n",
    "b = np.random.uniform(-20, 20, size=(3,4))\n",
    "\n",
    "actual = a @ b\n",
    "\n",
    "vec_quantized = nd_tensor_product(a,b, matrix = False)\n",
    "\n",
    "print(actual)\n",
    "print(vec_quantized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zeropoint or absmax Quantization together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matix_absmax_quantization(m1, int_type=np.int8):\n",
    "    data_max = np.iinfo(int_type).max\n",
    "    norm_range = math.floor((data_max)**(1/2)/ max(m1.shape))\n",
    "    quantification_constant = norm_range/np.max(abs(m1))\n",
    "    new_type = (m1 * quantification_constant).astype(int_type)\n",
    "    assert np.all((new_type >= -1*norm_range) & (new_type <= norm_range))\n",
    "    return new_type, quantification_constant\n",
    "\n",
    "def zeropoint_quantization(x, data_type):\n",
    "    data_range = np.iinfo(data_type).max- np.iinfo(data_type).min\n",
    "    q_c = data_range / (np.max(x)- np. min(x))\n",
    "    z_p = -1* np.round(q_c * np.min(x)) + np.iinfo(data_type).min\n",
    "    type_x = np.round(q_c * x + z_p).astype(data_type)\n",
    "    return type_x, q_c, z_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_quant_matmul(m1, m2, quantization_method):\n",
    "    matrix = np.empty((m1.shape[0], m2.shape[-1]))\n",
    "    for row_num in range(len(m1)):\n",
    "        for col_num in range(m2.shape[-1]):\n",
    "            row = m1[row_num]\n",
    "            col = m2[:, col_num]\n",
    "            if quantization_method == 'absmax':\n",
    "                int_row, row_const = matix_absmax_quantization(row, qualtization_type)\n",
    "                int_col, col_const = matix_absmax_quantization(col, qualtization_type)\n",
    "                int_dot = np.dot(int_row, int_col)\n",
    "                float_dot = int_dot.astype(np.float64)* 1/(row_const * col_const)\n",
    "            elif quantization_method == 'zeropoint':\n",
    "                int_row, row_const, row_zero = zeropoint_quantization(row, qualtization_type)\n",
    "                int_col, col_const, col_zero = zeropoint_quantization(col, qualtization_type)\n",
    "                int_dot = np.dot(int_row - row_zero, int_col- col_zero) # TODO Still multiplying in float64\n",
    "                float_dot = (int_dot /(row_const * col_const)).astype(np.float64)\n",
    "            if np.isnan(float_dot):\n",
    "                float_dot = 0\n",
    "            matrix[row_num][col_num] = float_dot\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def nd_tensor_product(m1, m2, quantization_method = 'absmax'):\n",
    "    ans_shape = m1.shape[:-2] + (m1.shape[-2], m2.shape[-1])\n",
    "    ans = np.empty(ans_shape)\n",
    "    if len(ans_shape) < 3:\n",
    "        return vector_quant_matmul(m1, m2, quantization_method)\n",
    "    else:\n",
    "        for i in range(ans_shape[0]):\n",
    "            ans[i] = nd_tensor_product(m1[i], m2[i], quantization_method=quantization_method)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% vec better 0.997\n",
      "abs loss 7.695771877807612\n",
      "zeropoint loss 0.05291885510640937\n"
     ]
    }
   ],
   "source": [
    "iterations = 1000\n",
    "qualtization_type = np.int8\n",
    "\n",
    "absmax_diff = 0\n",
    "zeropoint_diff = 0\n",
    "\n",
    "zeropoint_smaller = 0\n",
    "for _ in range(iterations):\n",
    "    a = np.random.uniform(-20, 20, size=(2, 10, 4))\n",
    "    b = np.random.uniform(-20, 20, size=(2, 4, 10))\n",
    "\n",
    "    actual = a @ b\n",
    "\n",
    "    absmax_quantized = nd_tensor_product(a,b, quantization_method = 'absmax')\n",
    "    absmax_loss = np.abs(np.mean(absmax_quantized - actual))\n",
    "    absmax_diff += absmax_loss\n",
    "\n",
    "    zeropoint_quantized = nd_tensor_product(a,b, quantization_method = 'zeropoint')\n",
    "    zeropoint_loss = np.abs(np.mean(zeropoint_quantized - actual))\n",
    "    zeropoint_diff += zeropoint_loss\n",
    "    if zeropoint_loss < absmax_loss:\n",
    "        zeropoint_smaller += 1\n",
    "\n",
    "\n",
    "print(f'% vec better {zeropoint_smaller/iterations}')\n",
    "print(f'abs loss {absmax_diff/iterations}')\n",
    "print(f'zeropoint loss {zeropoint_diff/iterations}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
