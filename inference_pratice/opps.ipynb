{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "total = [0]\n",
    "def my_matmult(m1, m2):\n",
    "    ans_mat = np.empty((0,m2.shape[1]))\n",
    "    for row in m1:\n",
    "        ans_row = np.array([])\n",
    "        for col in m2.T:\n",
    "            ans_row = np.append(ans_row, np.dot(row, col))\n",
    "            total[0] += len(row)*2\n",
    "        ans_mat = np.vstack((ans_mat,ans_row))\n",
    "    return ans_mat\n",
    "\n",
    "a = np.random.rand(3, 2)\n",
    "b = np.random.rand(2, 3)\n",
    "\n",
    "print(np.array_equal(a@b, my_matmult(a,b)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def tensor_product(m1, m2):\n",
    "  ans = np.empty( (0, m1.shape[-2], m2.shape[-1]) )\n",
    "  for i in range(m1.shape[0]):\n",
    "    matmult = np.expand_dims(my_matmult(m1[i], m2[i]), axis=0)\n",
    "    ans = np.vstack((ans, matmult))\n",
    "  return ans\n",
    "\n",
    "a = np.random.rand(2, 3, 4)\n",
    "b = np.random.rand(2, 4, 2)\n",
    "\n",
    "print(np.allclose(tensor_product(a,b), a @ b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[24576]\n"
     ]
    }
   ],
   "source": [
    "def nd_tensor_product(m1, m2):\n",
    "  ans_shape = m1.shape[:-2] + (m1.shape[-2], m2.shape[-1])\n",
    "  ans = np.empty(ans_shape)\n",
    "  for i in range(m1.shape[0]):\n",
    "    if len(m1.shape) == 3:\n",
    "        ans[i] = my_matmult(m1[i], m2[i])\n",
    "\n",
    "    else:\n",
    "        ans[i] = nd_tensor_product(m1[i], m2[i])\n",
    "  return ans\n",
    "\n",
    "a = np.random.rand(12, 4, 64)\n",
    "b = np.random.rand(12, 64, 4)\n",
    "\n",
    "total = [0]\n",
    "\n",
    "print(np.allclose(nd_tensor_product(a,b), a @ b))\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matix_absmax_quantization(m1, int_type=np.int8):\n",
    "    data_max = np.iinfo(int_type).max\n",
    "    norm_range = math.floor((data_max)**(1/2)/ max(m1.shape))\n",
    "    quantification_constant = norm_range/np.max(abs(m1))\n",
    "    new_type = (m1 * quantification_constant).astype(int_type)\n",
    "    assert np.all((new_type >= -1*norm_range) & (new_type <= norm_range))\n",
    "\n",
    "    return new_type, quantification_constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_quant_matmul(m1, m2):\n",
    "    m1, m1_const = matix_absmax_quantization(m1, qualtization_type)\n",
    "    m2, m2_const = matix_absmax_quantization(m2, qualtization_type)\n",
    "\n",
    "    ans = np.matmul(m1,m2)\n",
    "\n",
    "    ans = (ans.astype(np.float64))/ (m1_const * m2_const)\n",
    "    return ans\n",
    "\n",
    "def vector_quant_matmul(m1, m2):\n",
    "    matrix = np.empty((m1.shape[0], m2.shape[-1]))\n",
    "    for row_num in range(len(m1)):\n",
    "        for col_num in range(m2.shape[-1]):\n",
    "            row = m1[row_num]\n",
    "            col = m2[:, col_num]\n",
    "            int_row, row_const = matix_absmax_quantization(row, qualtization_type)\n",
    "            int_col, col_const = matix_absmax_quantization(col, qualtization_type)\n",
    "            int_dot = np.dot(int_row, int_col)\n",
    "            float_dot = int_dot.astype(np.float64)* 1/(row_const * col_const)\n",
    "            if np.isnan(float_dot):\n",
    "                float_dot = 0\n",
    "            matrix[row_num][col_num] = float_dot\n",
    "    return matrix\n",
    "\n",
    "def nd_tensor_product(m1, m2, matrix = True):\n",
    "    ans_shape = m1.shape[:-2] + (m1.shape[-2], m2.shape[-1])\n",
    "    ans = np.empty(ans_shape)\n",
    "    if len(ans_shape) < 3:\n",
    "        return matrix_quant_matmul(m1, m2) if matrix else vector_quant_matmul(m1, m2)\n",
    "    else:\n",
    "        for i in range(ans_shape[0]):\n",
    "            ans[i] = nd_tensor_product(m1[i], m2[i])\n",
    "    return ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 37.82110668 -67.31442379  69.34831837]\n",
      "[ 78.94985696 -80.60999366   8.19402079]\n",
      "8980.427799868674\n",
      "8980.427781856803\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[ 37.82110668, -67.31442379,  69.34831837],\n",
    " [-88.51179468,  63.74114025,  4.15519527]])\n",
    "b = np.array([[ 57.14724296,  78.94985696, -38.34095173, -31.81479472, -69.31694691],\n",
    " [-49.47479473 ,-80.60999366,  58.50876067 , 56.40911124,  92.51044183],\n",
    " [-94.53736112 ,  8.19402079 ,-82.28626678 , -5.34393604, -47.48347282]])\n",
    "\n",
    "qualtization_type = np.int64\n",
    "\n",
    "print(a[0])\n",
    "print(b[:, 1])\n",
    "actual = np.dot(a[0], b[:, 1])\n",
    "\n",
    "m1, m1_const = matix_absmax_quantization(a[0], qualtization_type)\n",
    "m2, m2_const = matix_absmax_quantization(b[:, 1], qualtization_type)\n",
    "int_ans = np.dot(m1,m2)\n",
    "\n",
    "ans = (int_ans.astype(np.float64))/ (m1_const * m2_const)\n",
    "\n",
    "\n",
    "\n",
    "print(actual)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% vec better 0.0\n",
      "mtx loss 0.3364990468150585\n",
      "vec loss 0.3364990468150585\n"
     ]
    }
   ],
   "source": [
    "vec_smaller = 0\n",
    "iterations = 1000\n",
    "qualtization_type = np.int16\n",
    "\n",
    "matrix_diff = 0\n",
    "vec_diff = 0\n",
    "\n",
    "\n",
    "for _ in range(iterations):\n",
    "    a = np.random.uniform(-10, 10, size=(2, 10, 4))\n",
    "    b = np.random.uniform(-10, 10, size=(2, 4, 10))\n",
    "\n",
    "    actual = a @ b\n",
    "    print(actual)\n",
    "\n",
    "    mx_quantized = nd_tensor_product(a,b, matrix = True)\n",
    "    # print(f\"{mx_quantized=}\")\n",
    "    mx_loss = np.abs(np.mean(mx_quantized - actual))\n",
    "    matrix_diff += mx_loss\n",
    "    # print(f'matrix loss: {mx_loss}')\n",
    "\n",
    "    vec_quantized = nd_tensor_product(a,b, matrix = False)\n",
    "    # print(f\"{vec_quantized=}\")\n",
    "    vec_loss = np.abs(np.mean(vec_quantized - actual))\n",
    "    # print(vec_loss)\n",
    "    vec_diff += vec_loss\n",
    "    # print(f'vec loss: {vec_loss}')\n",
    "    if vec_loss < mx_loss:\n",
    "        vec_smaller += 1\n",
    "\n",
    "\n",
    "print(f'% vec better {vec_smaller/iterations}')\n",
    "print(f'mtx loss {matrix_diff/iterations}')\n",
    "print(f'vec loss {vec_diff/iterations}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "descriptor 'astype' for 'numpy.generic' objects doesn't apply to a 'type' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[322], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m row_const \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      3\u001b[0m col_const \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 4\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mint_dot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m/\u001b[39m(row_const \u001b[38;5;241m*\u001b[39m col_const)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(a)\n",
      "\u001b[0;31mTypeError\u001b[0m: descriptor 'astype' for 'numpy.generic' objects doesn't apply to a 'type' object"
     ]
    }
   ],
   "source": [
    "int_dot = np.float64\n",
    "row_const = 0\n",
    "col_const = 1\n",
    "a = int_dot.astype(np.float64)/(row_const * col_const)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
