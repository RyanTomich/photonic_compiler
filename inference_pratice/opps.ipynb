{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "total = [0]\n",
    "def my_matmult(m1, m2):\n",
    "    ans_mat = np.empty((0,m2.shape[1]))\n",
    "    for row in m1:\n",
    "        ans_row = np.array([])\n",
    "        for col in m2.T:\n",
    "            ans_row = np.append(ans_row, np.dot(row, col))\n",
    "            total[0] += len(row)*2\n",
    "        ans_mat = np.vstack((ans_mat,ans_row))\n",
    "    return ans_mat\n",
    "\n",
    "a = np.random.rand(3, 2)\n",
    "b = np.random.rand(2, 3)\n",
    "\n",
    "print(np.array_equal(a@b, my_matmult(a,b)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def tensor_product(m1, m2):\n",
    "  ans = np.empty( (0, m1.shape[-2], m2.shape[-1]) )\n",
    "  for i in range(m1.shape[0]):\n",
    "    matmult = np.expand_dims(my_matmult(m1[i], m2[i]), axis=0)\n",
    "    ans = np.vstack((ans, matmult))\n",
    "  return ans\n",
    "\n",
    "a = np.random.rand(2, 3, 4)\n",
    "b = np.random.rand(2, 4, 2)\n",
    "\n",
    "print(np.allclose(tensor_product(a,b), a @ b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "True\n",
      "[24576]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def nd_tensor_product(m1, m2):\n",
    "  ans_shape = m1.shape[:-2] + (m1.shape[-2], m2.shape[-1])\n",
    "  ans = np.empty(ans_shape)\n",
    "  for i in range(m1.shape[0]):\n",
    "    if len(m1.shape) == 3:\n",
    "        ans[i] = my_matmult(m1[i], m2[i])\n",
    "\n",
    "    else:\n",
    "        ans[i] = nd_tensor_product(m1[i], m2[i])\n",
    "  return ans\n",
    "\n",
    "a = np.random.rand(12, 4, 64)\n",
    "b = np.random.rand(12, 64, 4)\n",
    "\n",
    "total = [0]\n",
    "\n",
    "print(np.allclose(nd_tensor_product(a,b), a @ b))\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tensor_elements(tensor_shape):\n",
    "    ans = 1\n",
    "    for dimention in tensor_shape:\n",
    "        ans *= dimention\n",
    "    return ans\n",
    "\n",
    "\n",
    "# max(out, key=len)\n",
    "\n",
    "opp_time_func = {\n",
    "    'add': lambda i, o: tensor_elements(o),\n",
    "    'subtract': lambda i, o: tensor_elements(o),\n",
    "    'multiply': lambda i, o: tensor_elements(o),\n",
    "    'divide': lambda i, o:  tensor_elements(o),\n",
    "    'rsqrt': lambda i, o: tensor_elements(o),\n",
    "    'power': lambda i, o: tensor_elements(o),\n",
    "    'mean': lambda i, o: 0, # TODO\n",
    "    'nop': lambda i, o: 0, #reshape(Non-Computational)\n",
    "    'less': lambda i, o: 1,\n",
    "    'where': lambda i, o: 1,\n",
    "    'take': lambda i, o: 1,\n",
    "    'softmax': lambda i, o: 6*i[0][-1]*i[0][-2],\n",
    "    # 'matmul': lambda i, o: tensor_elements(i[0])*i[0][-1]*i[1][-2],\n",
    "    'matmul': lambda i, o: tensor_elements(i[0])*i[1][-2]*2,\n",
    "    'transpose': lambda i, o: 0,\n",
    "    'split': lambda i, o: 0,\n",
    "    'dense': lambda i, o: 0,\n",
    "    'tanh': lambda i, o: 0,\n",
    "}\n",
    "\n",
    "input_shapes = [[12, 4, 64], [12, 4, 64]]\n",
    "output_shape = []\n",
    "cycles = opp_time_func['matmul'](input_shapes, output_shape)\n",
    "cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24576"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12*4*4*64*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12*4*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
